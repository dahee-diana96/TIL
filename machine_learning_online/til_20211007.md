# Chapter 01. 자동으로 모은 데이터는 분석하기 어렵다면서? 자동으로 모은 중고 자동차 데이터를 분석해보자!

[데이터 출처](https://www.kaggle.com/austinreese/craigslist-carstrucks-data)

# Step 3. 데이터 클리닝 수행하기
- `sns.heatmap(df.corr(), annot=True, cmap='YlOrRd')`
> cmap: The mapping from data values to color space. If not provided, the default will depend on whether center is set. (from seaborn official website)

# Step 4. 모델 학습을 위한 데이터 전처리
- `X.fillna(0.0, inplace=True)`
    - `X.mean()`을 구한 결과, 0에 매우 가까운 값이였으므로 평균값인 0을 na 자리에 채우는 작업을 함

# Step 5. Regression 모델 학습하기
- `mean_abolute_error(y_test, pred)`
    - [참고 링크](https://mizykk.tistory.com/102)
    - Mean Absolute Error (MAE)
    - 실제 값과 예측 값의 차이(Error)를 절대값으로 변환해 평균화
    - 에러에 따른 손실이 선형적으로 올라갈 때 적합
    - 이상치가 많을 때
- `sqrt(mean_squared_error(y_test, pred))`
    - [참고 링크](https://blog.naver.com/owl6615/221537580561)
> 입력변수가 하나일 땐 최소제곱법의 공식을 이용해 기울기와 회귀상수를 구할 수 있지만, 입력변수가 여러 개일 때는 최소제곱법으로는 무리가 있다. 그리고 대부분의 데이터셋은 절대적으로 입력변수가 여러 개이다. 이런 경우 오차를 가장 최소화하는 최적선을 그리기 위해 평균 제곱근 오차 (Root mean square error)를 사용한다.

# Step 6. 모델 학습 결과 심화 분석하기
- ``plt.scatter(x=y_test, y=pred, alpha=0.005)
plt.plot([0,60000], [0,60000], 'r-')``

- ``err = (pred - y_test) / y_test
sns.histplot(err)
plt.xlabel('error (%)')
plt.xlim(-100,100)``
    - 두 코드를 각각 돌려서 나오는 그래프를 통해 학습한 결과들이 얼마나 underestimate됐는지를 알 수 있음
    - histplot같은 경우 에러율이 양과 음의 방향으로 퍼져 있다는 것을 알 수 있음
    - best case: ‘0’에 기둥 하나만 딱 있는 모습의 histplot

